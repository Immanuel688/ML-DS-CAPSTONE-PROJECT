{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "111cb8fc-f829-4ade-8a39-01f24022a3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44573de4-751b-431e-a277-5a299285c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rfeFeature(indep_X,dep_Y,n):\n",
    "        rfelist=[]\n",
    "        \n",
    "        log_model = LogisticRegression(solver='lbfgs')\n",
    "        RF = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        # NB = GaussianNB()\n",
    "        DT= DecisionTreeClassifier(criterion = 'gini', max_features='sqrt',splitter='best',random_state = 0)\n",
    "        XGB= XGBClassifier(objective='binary:logistic',max_depth= 5,learning_rate=0.1,subsample=1,n_estimators=100)\n",
    "        #svc_model = SVC(kernel = 'linear', random_state = 0)\n",
    "        #knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "        rfemodellist=[log_model,RF,DT,XGB] \n",
    "        for i in   rfemodellist:\n",
    "            print(i)\n",
    "            log_rfe = RFE(i, n_features_to_select=n)\n",
    "            log_fit = log_rfe.fit(indep_X, dep_Y)\n",
    "            log_rfe_feature=log_fit.transform(indep_X)\n",
    "            rfelist.append(log_rfe_feature)\n",
    "        return rfelist\n",
    "    \n",
    "\n",
    "def split_scalar(indep_X,dep_Y):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(indep_X, dep_Y, test_size = 0.2, random_state = 0)\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(indep_X,dep_Y, test_size = 0.25, random_state = 0)\n",
    "        \n",
    "        #Feature Scaling\n",
    "        #from sklearn.preprocessing import StandardScaler\n",
    "        #sc = StandardScaler()\n",
    "        #X_train = sc.fit_transform(X_train)\n",
    "        #X_test = sc.transform(X_test)\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    \n",
    "def cm_prediction(classifier,X_test):\n",
    "     y_pred = classifier.predict(X_test)\n",
    "        \n",
    "        # Making the Confusion Matrix\n",
    "     from sklearn.metrics import confusion_matrix\n",
    "     cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     from sklearn.metrics import accuracy_score \n",
    "     from sklearn.metrics import classification_report \n",
    "        #from sklearn.metrics import confusion_matrix\n",
    "        #cm = confusion_matrix(y_test, y_pred)\n",
    "        \n",
    "     Accuracy=accuracy_score(y_test, y_pred )\n",
    "        \n",
    "     report=classification_report(y_test, y_pred)\n",
    "     return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "def logistic(X_train,y_train,X_test):       \n",
    "        # Fitting K-NN to the Training set\n",
    "        from sklearn.linear_model import LogisticRegression\n",
    "        classifier = LogisticRegression(random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "    \n",
    "def Decision(X_train,y_train,X_test):\n",
    "        \n",
    "        from sklearn.tree import DecisionTreeClassifier\n",
    "        classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm      \n",
    "\n",
    "\n",
    "def random(X_train,y_train,X_test):\n",
    "        \n",
    "        from sklearn.ensemble import RandomForestClassifier\n",
    "        classifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm\n",
    "\n",
    "def Xgboost(X_train,y_train,X_test):\n",
    "        import xgboost\n",
    "        from xgboost import XGBClassifier\n",
    "        from collections import Counter\n",
    "        counter = Counter(y_train)  # Count class occurrences\n",
    "        ratio = counter[0] / counter[1]\n",
    "        classifier = XGBClassifier(objective='binary:logistic',max_depth= 5,learning_rate=0.1,subsample=1,n_estimators=100) #,scale_pos_weight=ratio)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        classifier,Accuracy,report,X_test,y_test,cm=cm_prediction(classifier,X_test)\n",
    "        return  classifier,Accuracy,report,X_test,y_test,cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a876b56b-080e-4e01-aa5f-5f955b7f26b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99c0ef75-0cb9-497a-9900-e74693cff40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= pd.read_csv(\"Preprocessed_dataset.csv\")\n",
    "dataset1=pd.get_dummies(dataset,drop_first=True,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca060d8d-e087-432b-97fe-c1714276cc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "indep_x= dataset1.drop('Conversion',axis=1)\n",
    "dep_y=dataset1['Conversion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5dfecf75-34a3-45e3-9cdb-4cba2e5dd0e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "RandomForestClassifier(criterion='entropy', n_estimators=10, random_state=0)\n",
      "DecisionTreeClassifier(max_features='sqrt', random_state=0)\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[0.04391851, 0.08803141, 2.39901653, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.15572507, 0.18272468, 2.91713775, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.27749037, 0.07642272, 8.2236191 , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.05652592, 0.13382612, 2.85324058, ..., 1.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.02396129, 0.13838618, 1.00296447, ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.1856701 , 0.05722808, 6.96473936, ..., 0.        , 0.        ,\n",
       "         0.        ]]),\n",
       " array([[1.36912000e+05, 6.49787007e+03, 4.39185107e-02, ...,\n",
       "         6.00000000e+00, 4.00000000e+00, 6.88000000e+02],\n",
       "        [4.17600000e+04, 3.89866861e+03, 1.55725071e-01, ...,\n",
       "         2.00000000e+00, 2.00000000e+00, 3.45900000e+03],\n",
       "        [8.84560000e+04, 1.54642960e+03, 2.77490369e-01, ...,\n",
       "         1.10000000e+01, 8.00000000e+00, 2.33700000e+03],\n",
       "        ...,\n",
       "        [1.25471000e+05, 4.60953464e+03, 5.65259173e-02, ...,\n",
       "         1.60000000e+01, 3.00000000e+00, 7.38000000e+02],\n",
       "        [1.07862000e+05, 9.47610635e+03, 2.39612921e-02, ...,\n",
       "         1.00000000e+00, 7.00000000e+00, 2.70900000e+03],\n",
       "        [9.30020000e+04, 7.74362707e+03, 1.85670096e-01, ...,\n",
       "         1.80000000e+01, 9.00000000e+00, 3.41000000e+02]]),\n",
       " array([[1.36912000e+05, 6.49787007e+03, 4.39185107e-02, ...,\n",
       "         6.00000000e+00, 4.00000000e+00, 6.88000000e+02],\n",
       "        [4.17600000e+04, 3.89866861e+03, 1.55725071e-01, ...,\n",
       "         2.00000000e+00, 2.00000000e+00, 3.45900000e+03],\n",
       "        [8.84560000e+04, 1.54642960e+03, 2.77490369e-01, ...,\n",
       "         1.10000000e+01, 8.00000000e+00, 2.33700000e+03],\n",
       "        ...,\n",
       "        [1.25471000e+05, 4.60953464e+03, 5.65259173e-02, ...,\n",
       "         1.60000000e+01, 3.00000000e+00, 7.38000000e+02],\n",
       "        [1.07862000e+05, 9.47610635e+03, 2.39612921e-02, ...,\n",
       "         1.00000000e+00, 7.00000000e+00, 2.70900000e+03],\n",
       "        [9.30020000e+04, 7.74362707e+03, 1.85670096e-01, ...,\n",
       "         1.80000000e+01, 9.00000000e+00, 3.41000000e+02]]),\n",
       " array([[6.49787007e+03, 4.39185107e-02, 8.80314121e-02, ...,\n",
       "         9.00000000e+00, 4.00000000e+00, 0.00000000e+00],\n",
       "        [3.89866861e+03, 1.55725071e-01, 1.82724683e-01, ...,\n",
       "         7.00000000e+00, 2.00000000e+00, 0.00000000e+00],\n",
       "        [1.54642960e+03, 2.77490369e-01, 7.64227201e-02, ...,\n",
       "         2.00000000e+00, 8.00000000e+00, 0.00000000e+00],\n",
       "        ...,\n",
       "        [4.60953464e+03, 5.65259173e-02, 1.33826123e-01, ...,\n",
       "         0.00000000e+00, 3.00000000e+00, 0.00000000e+00],\n",
       "        [9.47610635e+03, 2.39612921e-02, 1.38386181e-01, ...,\n",
       "         5.00000000e+00, 7.00000000e+00, 0.00000000e+00],\n",
       "        [7.74362707e+03, 1.85670096e-01, 5.72280791e-02, ...,\n",
       "         9.00000000e+00, 9.00000000e+00, 0.00000000e+00]])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfelist=rfeFeature(indep_x,dep_y,10)\n",
    "rfelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5268b3ee-5557-4f40-831c-2395fb176d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  19  175]\n",
      " [   1 1405]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.10      0.18       194\n",
      "           1       0.89      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.92      0.55      0.56      1600\n",
      "weighted avg       0.90      0.89      0.85      1600\n",
      "\n",
      "[[  70  124]\n",
      " [ 137 1269]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.36      0.35       194\n",
      "           1       0.91      0.90      0.91      1406\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.62      0.63      0.63      1600\n",
      "weighted avg       0.84      0.84      0.84      1600\n",
      "\n",
      "[[  57  137]\n",
      " [  29 1377]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.29      0.41       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.79      0.64      0.68      1600\n",
      "weighted avg       0.88      0.90      0.88      1600\n",
      "\n",
      "[[  59  135]\n",
      " [  19 1387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.30      0.43       194\n",
      "           1       0.91      0.99      0.95      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.83      0.65      0.69      1600\n",
      "weighted avg       0.89      0.90      0.89      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   2 1404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.93      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  75  119]\n",
      " [ 144 1262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.39      0.36       194\n",
      "           1       0.91      0.90      0.91      1406\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.63      0.64      0.63      1600\n",
      "weighted avg       0.84      0.84      0.84      1600\n",
      "\n",
      "[[  55  139]\n",
      " [  32 1374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.28      0.39       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.77      0.63      0.67      1600\n",
      "weighted avg       0.87      0.89      0.87      1600\n",
      "\n",
      "[[  64  130]\n",
      " [  33 1373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.33      0.44       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.79      0.65      0.69      1600\n",
      "weighted avg       0.88      0.90      0.88      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   2 1404]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.93      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  75  119]\n",
      " [ 144 1262]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.39      0.36       194\n",
      "           1       0.91      0.90      0.91      1406\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.63      0.64      0.63      1600\n",
      "weighted avg       0.84      0.84      0.84      1600\n",
      "\n",
      "[[  55  139]\n",
      " [  32 1374]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.28      0.39       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.77      0.63      0.67      1600\n",
      "weighted avg       0.87      0.89      0.87      1600\n",
      "\n",
      "[[  64  130]\n",
      " [  33 1373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.33      0.44       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.79      0.65      0.69      1600\n",
      "weighted avg       0.88      0.90      0.88      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   0 1406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  78  116]\n",
      " [ 148 1258]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.40      0.37       194\n",
      "           1       0.92      0.89      0.91      1406\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.63      0.65      0.64      1600\n",
      "weighted avg       0.85      0.83      0.84      1600\n",
      "\n",
      "[[  56  138]\n",
      " [  33 1373]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.29      0.40       194\n",
      "           1       0.91      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.77      0.63      0.67      1600\n",
      "weighted avg       0.87      0.89      0.88      1600\n",
      "\n",
      "[[  79  115]\n",
      " [  17 1389]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.41      0.54       194\n",
      "           1       0.92      0.99      0.95      1406\n",
      "\n",
      "    accuracy                           0.92      1600\n",
      "   macro avg       0.87      0.70      0.75      1600\n",
      "weighted avg       0.91      0.92      0.90      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Xgboost(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b19bdca-56ac-4719-8b35-579f5a1bc350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  15  179]\n",
      " [   3 1403]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.08      0.14       194\n",
      "           1       0.89      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.86      0.54      0.54      1600\n",
      "weighted avg       0.88      0.89      0.84      1600\n",
      "\n",
      "[[  61  133]\n",
      " [ 132 1274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.31      0.32       194\n",
      "           1       0.91      0.91      0.91      1406\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.61      0.61      0.61      1600\n",
      "weighted avg       0.83      0.83      0.83      1600\n",
      "\n",
      "[[  55  139]\n",
      " [  51 1355]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.28      0.37       194\n",
      "           1       0.91      0.96      0.93      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.71      0.62      0.65      1600\n",
      "weighted avg       0.86      0.88      0.87      1600\n",
      "\n",
      "[[  48  146]\n",
      " [  23 1383]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.25      0.36       194\n",
      "           1       0.90      0.98      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.79      0.62      0.65      1600\n",
      "weighted avg       0.88      0.89      0.87      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   0 1406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  78  116]\n",
      " [ 150 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.40      0.37       194\n",
      "           1       0.92      0.89      0.90      1406\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.63      0.65      0.64      1600\n",
      "weighted avg       0.85      0.83      0.84      1600\n",
      "\n",
      "[[  60  134]\n",
      " [  42 1364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.41       194\n",
      "           1       0.91      0.97      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.75      0.64      0.67      1600\n",
      "weighted avg       0.87      0.89      0.87      1600\n",
      "\n",
      "[[  67  127]\n",
      " [  31 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.35      0.46       194\n",
      "           1       0.92      0.98      0.95      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.80      0.66      0.70      1600\n",
      "weighted avg       0.89      0.90      0.89      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   0 1406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  78  116]\n",
      " [ 150 1256]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.40      0.37       194\n",
      "           1       0.92      0.89      0.90      1406\n",
      "\n",
      "    accuracy                           0.83      1600\n",
      "   macro avg       0.63      0.65      0.64      1600\n",
      "weighted avg       0.85      0.83      0.84      1600\n",
      "\n",
      "[[  60  134]\n",
      " [  42 1364]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.31      0.41       194\n",
      "           1       0.91      0.97      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.75      0.64      0.67      1600\n",
      "weighted avg       0.87      0.89      0.87      1600\n",
      "\n",
      "[[  67  127]\n",
      " [  31 1375]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.35      0.46       194\n",
      "           1       0.92      0.98      0.95      1406\n",
      "\n",
      "    accuracy                           0.90      1600\n",
      "   macro avg       0.80      0.66      0.70      1600\n",
      "weighted avg       0.89      0.90      0.89      1600\n",
      "\n",
      "[[   0  194]\n",
      " [   0 1406]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       194\n",
      "           1       0.88      1.00      0.94      1406\n",
      "\n",
      "    accuracy                           0.88      1600\n",
      "   macro avg       0.44      0.50      0.47      1600\n",
      "weighted avg       0.77      0.88      0.82      1600\n",
      "\n",
      "[[  76  118]\n",
      " [ 132 1274]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.37      0.39      0.38       194\n",
      "           1       0.92      0.91      0.91      1406\n",
      "\n",
      "    accuracy                           0.84      1600\n",
      "   macro avg       0.64      0.65      0.64      1600\n",
      "weighted avg       0.85      0.84      0.85      1600\n",
      "\n",
      "[[  64  130]\n",
      " [  40 1366]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.33      0.43       194\n",
      "           1       0.91      0.97      0.94      1406\n",
      "\n",
      "    accuracy                           0.89      1600\n",
      "   macro avg       0.76      0.65      0.69      1600\n",
      "weighted avg       0.88      0.89      0.88      1600\n",
      "\n",
      "[[  76  118]\n",
      " [  19 1387]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.39      0.53       194\n",
      "           1       0.92      0.99      0.95      1406\n",
      "\n",
      "    accuracy                           0.91      1600\n",
      "   macro avg       0.86      0.69      0.74      1600\n",
      "weighted avg       0.91      0.91      0.90      1600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#10\n",
    "for i in rfelist:   \n",
    "    X_train, X_test, y_train, y_test=split_scalar(i,dep_y)   \n",
    "    \n",
    "        \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=logistic(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Decision(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=random(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)\n",
    "    \n",
    "    classifier,Accuracy,report,X_test,y_test,cm=Xgboost(X_train,y_train,X_test)\n",
    "    print(cm)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b89af0-3532-4e9c-923d-e524023a1db1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
